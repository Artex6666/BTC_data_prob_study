{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5556ec2",
   "metadata": {},
   "source": [
    "# Exploitation des déséquilibres Polymarket sur BTC\n",
    "\n",
    "Ce carnet assemble la chaîne complète : chargement des données, calibration d'un modèle de cotes FOMO, estimation de la probabilité réelle de clôture d'une bougie et backtests des stratégies 2 % capital et 4 % de parts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58c02c9",
   "metadata": {},
   "source": [
    "## Plan du carnet\n",
    "\n",
    "1. Chargement et préparation des données (1s et 1m)\n",
    "2. Simulation de cotes FOMO et visualisations\n",
    "3. Entraînement du modèle de cotes vs marché\n",
    "4. Entraînement du modèle de probabilité réelle\n",
    "5. Génération des cotes synthétiques historiques et backtests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c5250d",
   "metadata": {},
   "source": [
    "### Préparation des dépendances\n",
    "\n",
    "**Objectif** : charger toutes les fonctions utilitaires définies dans `notebooks/code` nécessaires au pipeline complet.\n",
    "\n",
    "**Sorties attendues** : aucune sortie directe. Les imports réussis garantissent que chaque module est disponible pour les cellules suivantes. En cas d'erreur, vérifier que les fichiers sont bien présents et que les dépendances Python sont installées.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28b7d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from code.pipeline import (\n",
    "    load_all_data,\n",
    "    prepare_ohlc_features,\n",
    "    enrich_polymarket_with_features,\n",
    "    prepare_timeframe_tables,\n",
    "    build_regression_dataset,\n",
    "    build_classification_dataset,\n",
    "    prepare_minute_history,\n",
    "    select_recent_rows,\n",
    "    make_fomo_input,\n",
    "    estimate_average_spreads,\n",
    ")\n",
    "from code.fomo_simulation import make_default_scenarios, simulate_fomo_odds\n",
    "from code.model_training import (\n",
    "    train_odds_regressors,\n",
    "    train_outcome_classifiers,\n",
    "    predict_regressions,\n",
    "    predict_classifications,\n",
    ")\n",
    "from code.backtest import BacktestParams, run_backtest\n",
    "from code.visualization import (\n",
    "    plot_odds_comparison,\n",
    "    plot_equity_curves,\n",
    "    plot_calibration_curve,\n",
    ")\n",
    "from code.persistence import (\n",
    "    export_regression_artifacts,\n",
    "    export_classification_artifacts,\n",
    ")\n",
    "from code.pricing import probabilities_to_prices\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970c69ae",
   "metadata": {},
   "source": [
    "### Chargement et enrichissement des données\n",
    "\n",
    "**Objectif** : lire les flux Polymarket (1 seconde) et les bougies BTC (1 minute), construire les features techniques, préparer les tables par horizon (m15, h1, daily) et stocker les structures intermédiaires utiles aux modèles.\n",
    "\n",
    "**Sorties attendues** : affichage des premières lignes de `polymarket_raw` et `ohlc_raw` pour valider le chargement. Des dictionnaires `regression_data`, `classification_data`, `fomo_inputs` ainsi que `minute_history` sont créés en mémoire pour une réutilisation par les cellules suivantes. Si certains champs sont `NaN`, vérifier la cohérence des horodatages ou ajuster `select_recent_rows`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953e2c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "polymarket_raw, ohlc_raw = load_all_data()\n",
    "polymarket_subset = select_recent_rows(polymarket_raw, 500_000)\n",
    "ohlc_features = prepare_ohlc_features(ohlc_raw)\n",
    "per_second_base = enrich_polymarket_with_features(polymarket_subset, ohlc_features)\n",
    "\n",
    "timeframes = [\"m15\", \"h1\", \"daily\"]\n",
    "per_second_full = per_second_base.copy()\n",
    "for tf in timeframes:\n",
    "    per_second_full = prepare_timeframe_tables(per_second_full, tf)\n",
    "\n",
    "average_spreads = estimate_average_spreads(per_second_full, timeframes)\n",
    "\n",
    "timeframe_tables = {}\n",
    "regression_data = {}\n",
    "classification_data = {}\n",
    "fomo_inputs = {}\n",
    "for tf in timeframes:\n",
    "    tf_df = prepare_timeframe_tables(per_second_base.copy(), tf)\n",
    "    timeframe_tables[tf] = tf_df\n",
    "    reg_dataset, reg_features, reg_targets = build_regression_dataset(tf_df, tf)\n",
    "    regression_data[tf] = {\n",
    "        \"dataset\": reg_dataset,\n",
    "        \"features\": reg_features,\n",
    "        \"targets\": reg_targets,\n",
    "    }\n",
    "    cls_dataset, cls_features, cls_target = build_classification_dataset(tf_df, tf)\n",
    "    classification_data[tf] = {\n",
    "        \"dataset\": cls_dataset,\n",
    "        \"features\": cls_features,\n",
    "        \"target\": cls_target,\n",
    "    }\n",
    "    fomo_inputs[tf] = make_fomo_input(tf_df, tf)\n",
    "\n",
    "minute_history = {tf: prepare_minute_history(ohlc_features, tf) for tf in timeframes}\n",
    "\n",
    "polymarket_raw.head(), ohlc_raw.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50d68fc",
   "metadata": {},
   "source": [
    "## Simulation FOMO calibrée sur les données réelles\n",
    "\n",
    "**Objectif** : générer des cotes théoriques à partir de scénarios FOMO (agressif, modéré, conservateur) en exploitant les probabilités et ATR issus des données historiques.\n",
    "\n",
    "**Sorties attendues** : les tables simulées contiendront pour chaque contrat une colonne `prob_up` (référence marché) et plusieurs colonnes `odds_*` représentant les variantes FOMO. Les estimations initiales de cote sont imprimées pour trois contrats par horizon afin de valider l’ancrage des simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d59c561",
   "metadata": {},
   "outputs": [],
   "source": [
    "fomo_scenarios = {tf: make_default_scenarios(tf) for tf in timeframes}\n",
    "fomo_results = {}\n",
    "for tf in timeframes:\n",
    "    fomo_results[tf] = simulate_fomo_odds(fomo_inputs[tf], fomo_scenarios[tf])\n",
    "\n",
    "initial_quotes = {\n",
    "    tf: (\n",
    "        fomo_results[tf].groupby(\"contract_id\").head(1)[\n",
    "            [\"timestamp\", \"prob_up\"] + [col for col in fomo_results[tf].columns if col.startswith(\"odds_\")]\n",
    "        ].head(3)\n",
    "    )\n",
    "    for tf in timeframes\n",
    "}\n",
    "\n",
    "initial_quotes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927b8127",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tf in timeframes:\n",
    "    scenario_cols = [col for col in fomo_results[tf].columns if col.startswith(\"odds_\")][:3]\n",
    "    figure = plot_odds_comparison(fomo_results[tf], tf, scenario_cols, \"prob_up\", n_samples=900)\n",
    "    display(figure)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3964a9fd",
   "metadata": {},
   "source": [
    "#### Visualisation des scénarios FOMO\n",
    "\n",
    "**Objectif** : comparer visuellement la convergence (ou divergence) entre les cotes simulées et la probabilité de marché pour chaque horizon (m15, h1, daily).\n",
    "\n",
    "**Sorties attendues** : trois graphiques ligne par ligne. Chaque figure affiche `prob_up` (marché) et les colonnes `odds_*` sélectionnées. Une proximité visuelle indique que le scénario reproduit bien la dynamique observée ; un écart persistant signale qu’il faut retuner les paramètres FOMO.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dacf72",
   "metadata": {},
   "source": [
    "## Modèle de cotes (régression)\n",
    "\n",
    "**Objectif** : entraîner, pour chaque horizon, un modèle de régression qui prédit le mid price Up/Down ainsi que la probabilité implicite du marché à partir des features techniques.\n",
    "\n",
    "**Sorties attendues** : un dictionnaire `regression_artifacts` contenant les pipelines scikit-learn et un tableau `regression_metrics` (MAE/RMSE par cible). Une faible MAE indique que le modèle reproduit correctement les cotes marché/FOMO.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff02ead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_artifacts = {}\n",
    "regression_metrics = {}\n",
    "for tf in timeframes:\n",
    "    artifacts = train_odds_regressors(\n",
    "        regression_data[tf][\"dataset\"],\n",
    "        regression_data[tf][\"features\"],\n",
    "        regression_data[tf][\"targets\"],\n",
    "    )\n",
    "    regression_artifacts[tf] = artifacts\n",
    "    regression_metrics[tf] = artifacts.metrics\n",
    "\n",
    "regression_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318e4363",
   "metadata": {},
   "source": [
    "#### Visualisation des cotes prédites\n",
    "\n",
    "**Objectif** : comparer les sorties des régressions (`pred_*`) aux probabilités implicites de marché pour évaluer qualitativement la calibration.\n",
    "\n",
    "**Sorties attendues** : trois graphiques (m15, h1, daily) affichant la cote de marché et les prédictions du modèle. Une superposition serrée valide la qualité du modèle ; de larges écarts signalent un besoin de features ou d’hyperparamètres supplémentaires.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b7d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_predictions = {}\n",
    "for tf in timeframes:\n",
    "    dataset = regression_data[tf][\"dataset\"].copy()\n",
    "    predictions = predict_regressions(regression_artifacts[tf], dataset)\n",
    "    regression_predictions[tf] = predictions\n",
    "    figure = plot_odds_comparison(\n",
    "        predictions.assign(prob_up=predictions[f\"{tf}_prob_up_market\"]),\n",
    "        tf,\n",
    "        [f\"pred_{target}\" for target in regression_artifacts[tf].target_columns],\n",
    "        \"prob_up\",\n",
    "        n_samples=600,\n",
    "    )\n",
    "    display(figure)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfee4460",
   "metadata": {},
   "source": [
    "## Modèle de probabilité réelle (classification)\n",
    "\n",
    "**Objectif** : estimer la probabilité « réelle » de clôture Up pour chaque contrat, en exploitant l’historique de prix et les features techniques, indépendamment de la cote de marché instantanée.\n",
    "\n",
    "**Sorties attendues** : un dictionnaire `classification_artifacts` et un tableau `classification_metrics` (AUC, accuracy, Brier). Une AUC > 0.5 indique une meilleure discrimination que le hasard, tandis qu’un Brier faible traduit une bonne calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7420291",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_artifacts = {}\n",
    "classification_metrics = {}\n",
    "for tf in timeframes:\n",
    "    artifacts = train_outcome_classifiers(\n",
    "        classification_data[tf][\"dataset\"],\n",
    "        classification_data[tf][\"features\"],\n",
    "        {tf: classification_data[tf][\"target\"]},\n",
    "    )\n",
    "    classification_artifacts[tf] = artifacts\n",
    "    classification_metrics[tf] = artifacts.metrics\n",
    "\n",
    "classification_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59efee4",
   "metadata": {},
   "source": [
    "#### Diagnostic de calibration\n",
    "\n",
    "**Objectif** : visualiser la calibration des probabilités prédites par les classifieurs sur l’échantillon de test.\n",
    "\n",
    "**Sorties attendues** : trois courbes de calibration où la diagonale représente une calibration parfaite. Si les points sont au-dessus (ou en dessous), le modèle sous-estime (ou surestime) la probabilité de clôture Up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a410148",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_predictions = {}\n",
    "for tf in timeframes:\n",
    "    dataset = classification_data[tf][\"dataset\"].copy()\n",
    "    preds = predict_classifications(classification_artifacts[tf], dataset)\n",
    "    classification_predictions[tf] = preds\n",
    "    calibration_fig = plot_calibration_curve(\n",
    "        preds,\n",
    "        f\"pred_proba_{tf}\",\n",
    "        classification_data[tf][\"target\"],\n",
    "    )\n",
    "    display(calibration_fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26886f8f",
   "metadata": {},
   "source": [
    "## Cotes synthétiques historiques et backtests\n",
    "\n",
    "**Objectif** : combiner les probabilités prédites avec les scénarios FOMO pour générer des cotes synthétiques historiques, puis évaluer deux stratégies (2 % capital / 4 % parts) via un backtest.\n",
    "\n",
    "**Sorties attendues** : dictionnaires `backtest_inputs` et `backtest_results` remplis pour chaque timeframe. Les résultats permettent d’analyser la rentabilité et la robustesse du modèle sur données historiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6391b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest_inputs = {}\n",
    "backtest_results = {}\n",
    "scenario_selection = {}\n",
    "\n",
    "for tf in timeframes:\n",
    "    minute_df = minute_history[tf].copy()\n",
    "    cls_dataset, minute_features, _ = build_classification_dataset(minute_df, tf)\n",
    "    model = classification_artifacts[tf].models[tf]\n",
    "    probabilities = model.predict_proba(cls_dataset[minute_features])[:, 1]\n",
    "    indices = cls_dataset[\"original_index\"].values\n",
    "    minute_df.loc[indices, f\"{tf}_prob_up_market\"] = probabilities\n",
    "    minute_df.loc[indices, \"pred_prob_up\"] = probabilities\n",
    "\n",
    "    fomo_input_minute = make_fomo_input(minute_df, tf)\n",
    "    fomo_simulated = simulate_fomo_odds(fomo_input_minute, fomo_scenarios[tf])\n",
    "    scenario_col = [col for col in fomo_simulated.columns if col.startswith(\"odds_\")][0]\n",
    "    scenario_selection[tf] = scenario_col\n",
    "\n",
    "    selected_rows = fomo_simulated.loc[indices].copy()\n",
    "    price_frame = probabilities_to_prices(\n",
    "        selected_rows[scenario_col],\n",
    "        average_spreads[tf][\"spread_up\"],\n",
    "        average_spreads[tf][\"spread_down\"],\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    backtest_frame = pd.DataFrame(\n",
    "        {\n",
    "            \"timestamp\": minute_df.loc[indices, \"timestamp\"].values,\n",
    "            \"prediction\": minute_df.loc[indices, \"pred_prob_up\"].values,\n",
    "            \"market_prob\": selected_rows[scenario_col].values,\n",
    "            \"outcome\": minute_df.loc[indices, f\"{tf}_target_up\"].values,\n",
    "        }\n",
    "    ).reset_index(drop=True)\n",
    "    backtest_frame = pd.concat([backtest_frame, price_frame], axis=1)\n",
    "    backtest_inputs[tf] = backtest_frame\n",
    "\n",
    "    params = BacktestParams(\n",
    "        timeframe=tf,\n",
    "        prediction_col=\"prediction\",\n",
    "        market_prob_col=\"market_prob\",\n",
    "        outcome_col=\"outcome\",\n",
    "        price_up_col=\"price_up_ask\",\n",
    "        price_down_col=\"price_down_ask\",\n",
    "        threshold=0.05,\n",
    "        initial_capital=1_000.0,\n",
    "        capital_risk_fraction=0.02,\n",
    "        share_fraction=0.04,\n",
    "    )\n",
    "    backtest_results[tf] = run_backtest(params, backtest_frame)\n",
    "\n",
    "backtest_inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d383c468",
   "metadata": {},
   "source": [
    "#### Synthèse tabulaire des backtests\n",
    "\n",
    "**Objectif** : consolider, pour chaque horizon, le nombre de trades, le winrate, le PnL total et l’équity finale pour les deux stratégies.\n",
    "\n",
    "**Sorties attendues** : un dictionnaire `backtest_summaries` où chaque `DataFrame` présente les colonnes `trades`, `winrate`, `total_pnl`, `final_equity`. Utilisez ces valeurs pour repérer les horizons les plus rentables ou instables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58cc176",
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest_summaries = {tf: result.summary for tf, result in backtest_results.items()}\n",
    "backtest_summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4152e57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tf in timeframes:\n",
    "    equity_fig = plot_equity_curves(backtest_results[tf])\n",
    "    display(equity_fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ff01d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_regression = {\n",
    "    tf: export_regression_artifacts(regression_artifacts[tf], prefix=f\"odds_{tf}\")\n",
    "    for tf in timeframes\n",
    "}\n",
    "exported_classification = {\n",
    "    tf: export_classification_artifacts(classification_artifacts[tf], prefix=f\"outcome_{tf}\")\n",
    "    for tf in timeframes\n",
    "}\n",
    "\n",
    "exported_regression, exported_classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc614ccd",
   "metadata": {},
   "source": [
    "## Synthèse rapide\n",
    "\n",
    "- Les métriques des modèles de cotes et de probabilité sont disponibles dans `regression_metrics` et `classification_metrics`.\n",
    "- Les backtests pour chaque horizon sont accessibles via `backtest_summaries` et les courbes d'équité.\n",
    "- Les modèles exportés (régression & classification) sont sauvegardés dans `models/` avec un préfixe par timeframe, utilisables directement via `code.main.run_live_inference`.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
