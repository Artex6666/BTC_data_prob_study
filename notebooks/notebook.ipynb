{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5556ec2",
   "metadata": {},
   "source": [
    "# Exploitation des déséquilibres Polymarket sur BTC\n",
    "\n",
    "Ce carnet assemble la chaîne complète : chargement des données, calibration d'un modèle de cotes FOMO, estimation de la probabilité réelle de clôture d'une bougie et backtests des stratégies 2 % capital et 4 % de parts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58c02c9",
   "metadata": {},
   "source": [
    "## Plan du carnet\n",
    "\n",
    "1. Chargement et préparation des données (1s et 1m)\n",
    "2. Simulation de cotes FOMO et visualisations\n",
    "3. Entraînement du modèle de cotes vs marché\n",
    "4. Entraînement du modèle de probabilité réelle\n",
    "5. Génération des cotes synthétiques historiques et backtests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c5250d",
   "metadata": {},
   "source": [
    "### Préparation des dépendances\n",
    "\n",
    "**Objectif** : charger toutes les fonctions utilitaires définies dans `notebooks/code` nécessaires au pipeline complet.\n",
    "\n",
    "**Sorties attendues** : aucune sortie directe. Les imports réussis garantissent que chaque module est disponible pour les cellules suivantes. En cas d'erreur, vérifier que les fichiers sont bien présents et que les dépendances Python sont installées.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28b7d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from btc_code.pipeline import (\n",
    "    load_all_data,\n",
    "    prepare_ohlc_features,\n",
    "    enrich_polymarket_with_features,\n",
    "    prepare_timeframe_tables,\n",
    "    build_regression_dataset,\n",
    "    build_classification_dataset,\n",
    "    prepare_minute_history,\n",
    "    select_recent_rows,\n",
    "    estimate_average_spreads,\n",
    ")\n",
    "from btc_code.model_training import (\n",
    "    train_odds_regressors,\n",
    "    train_outcome_classifiers,\n",
    "    predict_regressions,\n",
    "    predict_classifications,\n",
    ")\n",
    "from btc_code.backtest import BacktestParams, run_backtest\n",
    "from btc_code.visualization import (\n",
    "    plot_odds_comparison,\n",
    "    plot_equity_curves,\n",
    "    plot_calibration_curve,\n",
    ")\n",
    "from btc_code.persistence import (\n",
    "    export_regression_artifacts,\n",
    "    export_classification_artifacts,\n",
    ")\n",
    "from btc_code.pricing import probabilities_to_prices\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970c69ae",
   "metadata": {},
   "source": [
    "### Chargement et enrichissement des données\n",
    "\n",
    "**Objectif** : lire les flux Polymarket (1 seconde) et les bougies BTC (1 minute), construire les features techniques, préparer les tables par horizon (m15, h1, daily) et stocker les structures intermédiaires utiles aux modèles.\n",
    "\n",
    "**Sorties attendues** : affichage des premières lignes de `polymarket_raw` et `ohlc_raw` pour valider le chargement. Des dictionnaires `regression_data`, `classification_data` ainsi que `minute_history` sont créés en mémoire pour une réutilisation par les cellules suivantes. Si certains champs sont `NaN`, vérifier la cohérence des horodatages ou ajuster `select_recent_rows`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953e2c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "polymarket_raw, ohlc_raw = load_all_data()\n",
    "polymarket_subset = select_recent_rows(polymarket_raw, 500_000)\n",
    "ohlc_features = prepare_ohlc_features(ohlc_raw)\n",
    "per_second_base = enrich_polymarket_with_features(polymarket_subset, ohlc_features)\n",
    "\n",
    "timeframes = [\"m15\", \"h1\", \"daily\"]\n",
    "per_second_full = per_second_base.copy()\n",
    "for tf in timeframes:\n",
    "    per_second_full = prepare_timeframe_tables(per_second_full, tf)\n",
    "\n",
    "average_spreads = estimate_average_spreads(per_second_full, timeframes)\n",
    "\n",
    "timeframe_tables = {}\n",
    "regression_data = {}\n",
    "classification_data = {}\n",
    "for tf in timeframes:\n",
    "    tf_df = prepare_timeframe_tables(per_second_base.copy(), tf)\n",
    "    timeframe_tables[tf] = tf_df\n",
    "    reg_dataset, reg_features, reg_targets = build_regression_dataset(tf_df, tf)\n",
    "    regression_data[tf] = {\n",
    "        \"dataset\": reg_dataset,\n",
    "        \"features\": reg_features,\n",
    "        \"targets\": reg_targets,\n",
    "    }\n",
    "    cls_dataset, cls_features, cls_target = build_classification_dataset(tf_df, tf)\n",
    "    classification_data[tf] = {\n",
    "        \"dataset\": cls_dataset,\n",
    "        \"features\": cls_features,\n",
    "        \"target\": cls_target,\n",
    "    }\n",
    "\n",
    "minute_history = {tf: prepare_minute_history(ohlc_features, tf) for tf in timeframes}\n",
    "\n",
    "polymarket_raw.head(), ohlc_raw.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50d68fc",
   "metadata": {},
   "source": [
    "## Sélection des contrats pour la comparaison marché / modèle\n",
    "\n",
    "**Objectif** : choisir les identifiants de contrats (m15, h1, daily) qui seront utilisés dans les graphiques de comparaison des cotes. Cela permet de naviguer facilement d’un pari à l’autre (par exemple trois contrats m15 consécutifs, deux contrats h1, un contrat daily couvrant une journée complète).\n",
    "\n",
    "**Sorties attendues** : un dictionnaire `selected_contracts` que l’on peut modifier à la main : changer l’ordre, le nombre ou les identifiants affichés selon les périodes que l’on souhaite analyser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d59c561",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_contracts = list(timeframe_tables[\"daily\"][\"daily_contract_id\"].dropna().unique())\n",
    "selected_contracts = {\n",
    "    \"m15\": list(timeframe_tables[\"m15\"][\"m15_contract_id\"].dropna().unique()[:3]),\n",
    "    \"h1\": list(timeframe_tables[\"h1\"][\"h1_contract_id\"].dropna().unique()[:2]),\n",
    "    \"daily\": daily_contracts[:1],\n",
    "}\n",
    "\n",
    "selected_contracts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927b8127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Astuce : ajuster manuellement les identifiants dans `selected_contracts`\n",
    "# pour naviguer d’un pari à l’autre (contrats m15, h1, daily).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3964a9fd",
   "metadata": {},
   "source": [
    "#### Visualisation des cotes marché vs modèle ML\n",
    "\n",
    "**Objectif** : tracer, pour chaque horizon et pour les contrats sélectionnés, la cote implicite du marché et celle prédite par le modèle de régression. Les segments sont tracés contrat par contrat pour éviter les liaisons artificielles entre deux paris distincts.\n",
    "\n",
    "**Sorties attendues** : trois graphiques (m15, h1, daily) dont le titre affiche « Comparaison des cotes <timeframe> » et la date du jour au format « 12 novembre ». L’axe Y est libellé « Probabilité de clôture UP » et chaque série (marché, modèle) dispose d’une légende explicite.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dacf72",
   "metadata": {},
   "source": [
    "## Modèle de cotes (régression)\n",
    "\n",
    "**Objectif** : entraîner, pour chaque horizon, un modèle de régression qui prédit le mid price Up/Down ainsi que la probabilité implicite du marché à partir des features techniques.\n",
    "\n",
    "**Sorties attendues** : un dictionnaire `regression_artifacts` contenant les pipelines scikit-learn et un tableau `regression_metrics` (MAE/RMSE par cible). Une faible MAE indique que le modèle reproduit correctement les cotes marché/FOMO.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff02ead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_artifacts = {}\n",
    "regression_metrics = {}\n",
    "for tf in timeframes:\n",
    "    artifacts = train_odds_regressors(\n",
    "        regression_data[tf][\"dataset\"],\n",
    "        regression_data[tf][\"features\"],\n",
    "        regression_data[tf][\"targets\"],\n",
    "    )\n",
    "    regression_artifacts[tf] = artifacts\n",
    "    regression_metrics[tf] = artifacts.metrics\n",
    "\n",
    "regression_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318e4363",
   "metadata": {},
   "source": [
    "#### Visualisation des cotes prédites\n",
    "\n",
    "**Objectif** : comparer les sorties du modèle de régression aux probabilités implicites du marché, en utilisant les contrats sélectionnés précédemment. Chaque contrat est tracé séparément afin d’éviter toute liaison entre deux paris distincts.\n",
    "\n",
    "**Sorties attendues** : trois graphiques (m15, h1, daily) affichant « Marché » vs « Modèle ML ». Les titres suivent le format « Comparaison des cotes <timeframe>\\n12 novembre » et l’axe Y est toujours « Probabilité de clôture UP ». Les segments reprennent à 50 % au début de chaque pari sans trait continu entre deux contrats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b7d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_predictions = {}\n",
    "for tf in timeframes:\n",
    "    dataset = regression_data[tf][\"dataset\"].copy()\n",
    "    predictions = predict_regressions(regression_artifacts[tf], dataset)\n",
    "    regression_predictions[tf] = predictions\n",
    "\n",
    "    original_idx = dataset[\"original_index\"]\n",
    "    target_alias = {\n",
    "        f\"{tf}_prob_up_market\": f\"{tf}_pred_prob_up_ml\",\n",
    "        f\"{tf}_price_up_mid\": f\"{tf}_pred_price_up_mid_ml\",\n",
    "        f\"{tf}_price_down_mid\": f\"{tf}_pred_price_down_mid_ml\",\n",
    "    }\n",
    "    for target, alias in target_alias.items():\n",
    "        pred_col = f\"pred_{target}\"\n",
    "        if pred_col in predictions.columns:\n",
    "            timeframe_tables[tf].loc[original_idx, alias] = predictions[pred_col].values\n",
    "\n",
    "    actual_col = f\"{tf}_prob_up_market\"\n",
    "    pred_col = f\"{tf}_pred_prob_up_ml\"\n",
    "    if pred_col not in timeframe_tables[tf].columns:\n",
    "        continue\n",
    "\n",
    "    contracts = [cid for cid in selected_contracts.get(tf, []) if cid]\n",
    "    label_map = {\n",
    "        actual_col: \"Marché\",\n",
    "        pred_col: \"Modèle ML\",\n",
    "    }\n",
    "    figure = plot_odds_comparison(\n",
    "        timeframe_tables[tf],\n",
    "        timeframe_label=tf.upper(),\n",
    "        predicted_cols=[pred_col],\n",
    "        actual_col=actual_col,\n",
    "        contract_col=f\"{tf}_contract_id\",\n",
    "        contract_ids=contracts if contracts else None,\n",
    "        label_map=label_map,\n",
    "    )\n",
    "    display(figure)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfee4460",
   "metadata": {},
   "source": [
    "## Modèle de probabilité réelle (classification)\n",
    "\n",
    "**Objectif** : estimer la probabilité « réelle » de clôture Up pour chaque contrat, en exploitant l’historique de prix et les features techniques, indépendamment de la cote de marché instantanée.\n",
    "\n",
    "**Sorties attendues** : un dictionnaire `classification_artifacts` et un tableau `classification_metrics` (AUC, accuracy, Brier). Une AUC > 0.5 indique une meilleure discrimination que le hasard, tandis qu’un Brier faible traduit une bonne calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7420291",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_artifacts = {}\n",
    "classification_metrics = {}\n",
    "for tf in timeframes:\n",
    "    artifacts = train_outcome_classifiers(\n",
    "        classification_data[tf][\"dataset\"],\n",
    "        classification_data[tf][\"features\"],\n",
    "        {tf: classification_data[tf][\"target\"]},\n",
    "    )\n",
    "    classification_artifacts[tf] = artifacts\n",
    "    classification_metrics[tf] = artifacts.metrics\n",
    "\n",
    "classification_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59efee4",
   "metadata": {},
   "source": [
    "#### Diagnostic de calibration\n",
    "\n",
    "**Objectif** : visualiser la calibration des probabilités prédites par les classifieurs sur l’échantillon de test.\n",
    "\n",
    "**Sorties attendues** : trois courbes de calibration où la diagonale représente une calibration parfaite. Si les points sont au-dessus (ou en dessous), le modèle sous-estime (ou surestime) la probabilité de clôture Up.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a410148",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_predictions = {}\n",
    "for tf in timeframes:\n",
    "    dataset = classification_data[tf][\"dataset\"].copy()\n",
    "    preds = predict_classifications(classification_artifacts[tf], dataset)\n",
    "    classification_predictions[tf] = preds\n",
    "    calibration_fig = plot_calibration_curve(\n",
    "        preds,\n",
    "        f\"pred_proba_{tf}\",\n",
    "        classification_data[tf][\"target\"],\n",
    "    )\n",
    "    display(calibration_fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26886f8f",
   "metadata": {},
   "source": [
    "## Cotes synthétiques historiques et backtests\n",
    "\n",
    "**Objectif** : combiner les probabilités prédites avec les scénarios FOMO pour générer des cotes synthétiques historiques, puis évaluer deux stratégies (2 % capital / 4 % parts) via un backtest.\n",
    "\n",
    "**Sorties attendues** : dictionnaires `backtest_inputs` et `backtest_results` remplis pour chaque timeframe. Les résultats permettent d’analyser la rentabilité et la robustesse du modèle sur données historiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6391b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest_inputs = {}\n",
    "backtest_results = {}\n",
    "\n",
    "for tf in timeframes:\n",
    "    minute_df = minute_history[tf].copy().sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "    market_series = (\n",
    "        timeframe_tables[tf][[\"timestamp\", f\"{tf}_prob_up_market\"]]\n",
    "        .dropna()\n",
    "        .sort_values(\"timestamp\")\n",
    "    )\n",
    "    minute_df = pd.merge_asof(\n",
    "        minute_df,\n",
    "        market_series,\n",
    "        on=\"timestamp\",\n",
    "        direction=\"backward\",\n",
    "        tolerance=pd.Timedelta(minutes=1),\n",
    "    )\n",
    "    minute_df.rename(columns={f\"{tf}_prob_up_market\": \"market_prob\"}, inplace=True)\n",
    "    minute_df[\"market_prob\"] = minute_df[\"market_prob\"].ffill().fillna(0.5)\n",
    "\n",
    "    cls_dataset, minute_features, _ = build_classification_dataset(minute_df, tf)\n",
    "    model = classification_artifacts[tf].models[tf]\n",
    "    probabilities = model.predict_proba(cls_dataset[minute_features])[:, 1]\n",
    "    indices = cls_dataset[\"original_index\"].values\n",
    "    minute_df.loc[indices, \"prediction\"] = probabilities\n",
    "\n",
    "    price_frame = probabilities_to_prices(\n",
    "        pd.Series(minute_df.loc[indices, \"market_prob\"].values),\n",
    "        average_spreads[tf][\"spread_up\"],\n",
    "        average_spreads[tf][\"spread_down\"],\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    backtest_frame = pd.DataFrame(\n",
    "        {\n",
    "            \"timestamp\": minute_df.loc[indices, \"timestamp\"].values,\n",
    "            \"prediction\": minute_df.loc[indices, \"prediction\"].values,\n",
    "            \"market_prob\": minute_df.loc[indices, \"market_prob\"].values,\n",
    "            \"outcome\": minute_df.loc[indices, f\"{tf}_target_up\"].values,\n",
    "        }\n",
    "    ).reset_index(drop=True)\n",
    "    backtest_frame = pd.concat([backtest_frame, price_frame], axis=1)\n",
    "    backtest_inputs[tf] = backtest_frame\n",
    "\n",
    "    params = BacktestParams(\n",
    "        timeframe=tf,\n",
    "        prediction_col=\"prediction\",\n",
    "        market_prob_col=\"market_prob\",\n",
    "        outcome_col=\"outcome\",\n",
    "        price_up_col=\"price_up_ask\",\n",
    "        price_down_col=\"price_down_ask\",\n",
    "        threshold=0.05,\n",
    "        initial_capital=1_000.0,\n",
    "        capital_risk_fraction=0.02,\n",
    "        share_fraction=0.04,\n",
    "    )\n",
    "    backtest_results[tf] = run_backtest(params, backtest_frame)\n",
    "\n",
    "backtest_inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d383c468",
   "metadata": {},
   "source": [
    "#### Synthèse tabulaire des backtests\n",
    "\n",
    "**Objectif** : consolider, pour chaque horizon, le nombre de trades, le winrate, le PnL total et l’équity finale pour les deux stratégies.\n",
    "\n",
    "**Sorties attendues** : un dictionnaire `backtest_summaries` où chaque `DataFrame` présente les colonnes `trades`, `winrate`, `total_pnl`, `final_equity`. Utilisez ces valeurs pour repérer les horizons les plus rentables ou instables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58cc176",
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest_summaries = {tf: result.summary for tf, result in backtest_results.items()}\n",
    "backtest_summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4152e57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tf in timeframes:\n",
    "    equity_fig = plot_equity_curves(backtest_results[tf])\n",
    "    display(equity_fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ff01d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_regression = {\n",
    "    tf: export_regression_artifacts(regression_artifacts[tf], prefix=f\"odds_{tf}\")\n",
    "    for tf in timeframes\n",
    "}\n",
    "exported_classification = {\n",
    "    tf: export_classification_artifacts(classification_artifacts[tf], prefix=f\"outcome_{tf}\")\n",
    "    for tf in timeframes\n",
    "}\n",
    "\n",
    "exported_regression, exported_classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc614ccd",
   "metadata": {},
   "source": [
    "## Synthèse rapide\n",
    "\n",
    "- Les métriques des modèles de cotes et de probabilité sont disponibles dans `regression_metrics` et `classification_metrics`.\n",
    "- Les backtests pour chaque horizon sont accessibles via `backtest_summaries` et les courbes d'équité.\n",
    "- Les modèles exportés (régression & classification) sont sauvegardés dans `models/` avec un préfixe par timeframe, utilisables directement via `code.main.run_live_inference`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
